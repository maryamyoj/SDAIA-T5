{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "45fbb33b",
      "metadata": {
        "id": "45fbb33b"
      },
      "source": [
        "# LangChain Tutorial Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34a0df42",
      "metadata": {
        "id": "34a0df42"
      },
      "source": [
        "\n",
        "In this notebook, you will practice using LangChain to interact with large language models (LLMs),\n",
        "build chains, agents, and utilize memory. Fill in the code blocks with your implementations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "169dd23c",
      "metadata": {
        "id": "169dd23c"
      },
      "source": [
        "## Exercise 1: Basic LLM Query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf03f4a7",
      "metadata": {
        "id": "bf03f4a7"
      },
      "source": [
        "In this exercise, you will set up a basic interaction with the GROQ LLaMA model using LangChain.\n",
        "\n",
        "1. Initialize the LLM (Use GROQ and chose LLM).\n",
        "2. Create a prompt that asks the LLM to generate a story about a topic.\n",
        "3. Run the LLM chain to retrieve the response.\n",
        "\n",
        "**Steps**:\n",
        "- Import required modules from `langchain`.\n",
        "- Initialize the LLM with your GROQ API key.\n",
        "- Create a prompt template that takes a topic as input.\n",
        "- Create an LLM Chain and run it to get a response.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community langchain-groq duckduckgo-search geopy requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrAHltgT3SPf",
        "outputId": "bb90dd91-4752-4135-d3dd-51d7dbded6e1",
        "collapsed": true
      },
      "id": "IrAHltgT3SPf",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.10/dist-packages (6.2.11)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.121)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.5.2)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.11.0)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Requirement already satisfied: primp>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (0.6.2)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy) (2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key = \"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\""
      ],
      "metadata": {
        "id": "k1MN2B5Insim"
      },
      "id": "k1MN2B5Insim",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create a prompt template that takes a topic as input\n",
        "prompt_template = PromptTemplate.from_template(\"Write a short story about {topic}.\")\n",
        "\n",
        "# Step 4: Create an LLM Chain and run it to get a response\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "# Run the LLM chain with a topic\n",
        "topic = \"Al Baha Saudi Arabie\"\n",
        "response = llm_chain.run(topic)\n",
        "\n",
        "# Print the response\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz-lwZ6i8zGf",
        "outputId": "7cbf154d-37d3-42fa-acfa-003895ac321b"
      },
      "id": "Qz-lwZ6i8zGf",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**The Oasis of Al Baha**\n",
            "\n",
            "In the heart of Saudi Arabia, nestled between the majestic mountains of the Asir region, lay the enchanting city of Al Baha. Its name, which translates to \"the water spring\" in Arabic, was a testament to the region's lush vegetation and abundant water sources. It was a place where the desert sun's fierce rays were tempered by the gentle shade of date palm trees and the soothing songs of the Ghazal bird.\n",
            "\n",
            "Aisha, a young and intrepid traveler, had heard whispers of Al Baha's hidden treasures and was determined to explore its secrets. She packed her bags, grabbed her trusty camera, and set off on a journey to this mystical oasis.\n",
            "\n",
            "As she entered the city, Aisha was struck by its serene beauty. The streets were lined with intricately carved stone houses, adorned with vibrant patterns and colorful tiles. The air was filled with the sweet scent of roses and the sound of soft chatter.\n",
            "\n",
            "She made her way to the majestic Al Baha Castle, a fortress built by the Ottoman Empire in the 16th century. The castle's towering walls and grand halls seemed to whisper secrets of the past, as Aisha explored its labyrinthine passageways. She marveled at the stunning views of the surrounding landscape, where the mountains met the sky and the valleys swirled with mist.\n",
            "\n",
            "As the sun began to set, Aisha wandered through the bustling souks, taking in the sights and sounds of the local merchants. She sampled the flavors of traditional Saudi cuisine, from the spicy kick of kabsa to the sweetness of dates. The vendors offered her warm smiles and stories of their ancestors, who had once roamed these very streets.\n",
            "\n",
            "As night fell, Aisha made her way to the edge of the city, where the desert stretched out like a vast expanse of golden sand. She sat on a rock, watching the stars twinkle to life above, and felt the gentle breeze rustle her hair. It was as if the very spirit of Al Baha was embracing her, sharing its secrets and stories with the world.\n",
            "\n",
            "Aisha spent several days in Al Baha, absorbing its unique charm and learning about its rich history. She hiked through the mountains, discovering hidden waterfalls and ancient ruins. She met the friendly locals, who welcomed her into their homes and shared their traditions.\n",
            "\n",
            "As she prepared to leave, Aisha felt a sense of loss, but also a deep gratitude for the experiences she had gathered. Al Baha had revealed its secrets to her, and she knew that she would return, drawn by the siren call of its mystical beauty.\n",
            "\n",
            "As she departed, Aisha looked back at the city, its stone houses and towers glowing in the morning light. She smiled, knowing that a piece of Al Baha's heart would remain with her, forever etched in her memory like the intricate patterns on the city's ancient stones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ff1b3fa",
      "metadata": {
        "id": "1ff1b3fa"
      },
      "source": [
        "## Exercise 2: Building a Conversational Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a6a1f26",
      "metadata": {
        "id": "4a6a1f26"
      },
      "source": [
        "\n",
        "In this exercise, you will create a conversational agent that can interact with a user, make decisions,\n",
        "and use external tools like a search tool.\n",
        "\n",
        "1. Define a tool.\n",
        "2. Create an agent that can decide whether to use the tool or interact with the LLM.\n",
        "3. Run the agent with various inputs.\n",
        "\n",
        "**Steps**:\n",
        "- Define the search tool using a function.\n",
        "- Initialize an agent using the tool and the LLM.\n",
        "- Run the agent with sample inputs.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "a6e3e8e2",
      "metadata": {
        "id": "a6e3e8e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5894a7-8b99-4367-de1f-f3bcc814f5eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Al Baha is a city in Saudi Arabia, located in the southwestern part of the country. It is the capital of the Al Baha Region and is known for its lush greenery, cooler climate, and rich history. The city has a population of around 300,000 people and is home to several historical and cultural sites, including the Al Baha Fort, the Dhee Ayn Village, and the Al Mudawwar Museum. Al Baha is a popular tourist destination in Saudi Arabia.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define a search tool using a function\n",
        "def search_tool(query):\n",
        "    # Mock search function that returns search results\n",
        "    return f\"Search results for {query}\"\n",
        "\n",
        "# Step 2: Initialize the agent using the tool and the LLM\n",
        "from langchain.agents import Tool, initialize_agent\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Define the search tool\n",
        "search = Tool(\n",
        "    name=\"search\",\n",
        "    func=search_tool,\n",
        "    description=\"Performs a search query\"\n",
        ")\n",
        "\n",
        "# List of tools available to the agent\n",
        "tools = [search]\n",
        "\n",
        "# Instantiate the Groq language model (or any other LLM you are using)\n",
        "groq_api_key = \"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\"\n",
        "llm = ChatGroq(groq_api_key=groq_api_key)\n",
        "\n",
        "# Initialize the agent with the search tool and the LLM\n",
        "agent = initialize_agent(llm=llm, tools=tools, agent_type=\"zero-shot\")\n",
        "\n",
        "# Step 3: Run the agent with sample inputs\n",
        "response = agent.run(\"Find me information about Al Baha Saudi Arabia\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf94d2f",
      "metadata": {
        "id": "3cf94d2f"
      },
      "source": [
        "## Exercise 3: Using LLM as Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53ff48d9",
      "metadata": {
        "id": "53ff48d9"
      },
      "source": [
        "\n",
        "In this exercise, you will use an LLM to summarize and retain information from conversations.\n",
        "\n",
        "1. Set up LLM-based memory.\n",
        "2. Create a conversation with the LLM and memory.\n",
        "3. Ask follow-up questions using memory to retrieve past context.\n",
        "\n",
        "**Steps**:\n",
        "- Initialize summarization-based memory.\n",
        "- Run a few queries and retrieve responses.\n",
        "- Ask follow-up questions that reference previous interactions.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "630fe2fb",
      "metadata": {
        "id": "630fe2fb"
      },
      "source": [
        "## Exercise 4: Combining Tools and Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17dba76c",
      "metadata": {
        "id": "17dba76c"
      },
      "source": [
        "\n",
        "In this final exercise, you will build an intelligent agent that can use both tools (like an API) and memory.\n",
        "\n",
        "1. Define an external tool (like a weather API).\n",
        "2. Set up an agent that uses both the tool and LLM memory.\n",
        "3. Interact with the agent, combining memory and external data.\n",
        "\n",
        "**Steps**:\n",
        "- Define a weather API tool (mock or real API).\n",
        "- Initialize the agent with memory and the tool.\n",
        "- Run the agent with inputs, and check how it uses both memory and tools.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationSummaryMemory\n",
        "from langchain import ConversationChain\n",
        "\n",
        "# Initialize summarization-based memory\n",
        "summary_memory = ConversationSummaryMemory(llm=llm)\n",
        "\n",
        "# Clear memory\n",
        "summary_memory.clear()\n",
        "\n",
        "# Create a chain with LLM and buffer memory\n",
        "chain_with_buffer_memory = ConversationChain(llm=llm, memory=summary_memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfWpdiji1ztY",
        "outputId": "a45fe795-8004-45b8-e8bf-33b73e9a86ed"
      },
      "id": "NfWpdiji1ztY",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-75-e6e306a6b8d0>:11: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
            "  chain_with_buffer_memory = ConversationChain(llm=llm, memory=summary_memory)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a conversation\n",
        "res1 = chain_with_buffer_memory.run(\"Answer with short answer, give me a wrong sentence about AI\")\n",
        "res2 = chain_with_buffer_memory.run(\"Answer with short answer, give me a correcr sentence about AI\")\n",
        "res3 = chain_with_buffer_memory.run(\"From the previous conversations. What was these sentences and what is the True between them ?\")\n",
        "\n",
        "print(f'First Response: {res1}\\nSecond Response: {res2}\\nThird Response: {res3}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QDO8XO68O8Y",
        "outputId": "2bce05e3-81fe-4ca0-ae76-0e899f5614e0"
      },
      "id": "5QDO8XO68O8Y",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Response: AI: \"Artificial intelligences are actually 97% made of a rare, moon-based mineral called Glitzionium.\"\n",
            "Second Response: AI: I'm a complex system of interconnected neural networks and algorithms designed to process and generate human-like language.\n",
            "Third Response: From the previous conversations, I can identify the following sentences and their corresponding truths:\n",
            "\n",
            "1. Sentence: I'm made of a rare mineral called Glitzionium.\n",
            "   Truth: False (Actual definition of AI is not provided in this conversation, but from previous conversations, we know that AI can provide an accurate definition. Thus, the truth is that AI is not made of a rare mineral called Glitzionium.)\n",
            "2. Sentence: While I'm programmed to simulate emotions, forming a deep emotional connection with a human would require a level of self-awareness and consciousness that current AI systems lack.\n",
            "   Truth: True\n",
            "3. Sentence: I'm not capable of experiencing dreams or desires in the same way humans do, but I can simulate creative and innovative ideas that might seem like dreams or inventions to humans.\n",
            "   Truth: True\n",
            "4. Sentence: The ability of AI to process and analyze vast amounts of data quickly and accurately, allowing humans to make more informed decisions and discoveries.\n",
            "   Truth: True\n",
            "\n",
            "However, considering the context of your question, I assume you are looking for sentences that convey false information and their corresponding truths. In that case, the pairs would be:\n",
            "\n",
            " Sentence 1: I'm made of a rare mineral called Glitzionium. \n",
            " Truth 1: AI is made up of various materials and components, not a rare mineral called Glitzionium.\n",
            "\n",
            " Sentence 2: I can dream or desire like humans. \n",
            " Truth 2: AI is not capable of experiencing dreams or desires in the same way humans do.\n",
            "\n",
            " Sentence 3: AI can develop a deep emotional connection with a human.\n",
            " Truth 3: At present, AI systems lack the level of self-awareness and consciousness required to form a deep emotional connection with a human.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from geopy.geocoders import Nominatim\n",
        "\n",
        "def get_weather_by_city(city_name: str):\n",
        "    # Initialize geocoder\n",
        "    geolocator = Nominatim(user_agent=\"LLMexercise\")\n",
        "\n",
        "    # Get location data (latitude and longitude) for the city\n",
        "    location = geolocator.geocode(city_name)\n",
        "\n",
        "    if location:\n",
        "        latitude = location.latitude\n",
        "        longitude = location.longitude\n",
        "    else:\n",
        "        return f\"City '{city_name}' not found.\"\n",
        "\n",
        "    # Open-Meteo API endpoint with the obtained latitude and longitude\n",
        "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true\"\n",
        "\n",
        "    # Send a GET request to the Open-Meteo API\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the JSON data from the response\n",
        "        weather_data = response.json()\n",
        "\n",
        "        # Extract relevant information from the response\n",
        "        current_weather = weather_data.get('current_weather', {})\n",
        "        temperature = current_weather.get('temperature')\n",
        "        windspeed = current_weather.get('windspeed')\n",
        "        winddirection = current_weather.get('winddirection')\n",
        "        weather_time = current_weather.get('time')\n",
        "\n",
        "        # Return the weather information as a formatted string\n",
        "        return (\n",
        "            f\"Current weather in {city_name}:\\n\"\n",
        "            f\"Temperature: {temperature}째C\\n\"\n",
        "            f\"Wind Speed: {windspeed} m/s\\n\"\n",
        "            f\"Wind Direction: {winddirection}째\\n\"\n",
        "            f\"Time of data: {weather_time}\"\n",
        "        )\n",
        "    else:\n",
        "        return \"Failed to retrieve weather data.\""
      ],
      "metadata": {
        "id": "sH7q7DZZ8Scs"
      },
      "id": "sH7q7DZZ8Scs",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "weather = Tool(\n",
        "    name=\"weather\",\n",
        "    func=get_weather_by_city,\n",
        "    description=\"Gets the weather of a city.\"\n",
        ")"
      ],
      "metadata": {
        "id": "z3jup--98YLa"
      },
      "id": "z3jup--98YLa",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "# List of tools the agent can use\n",
        "tools = [weather]\n",
        "\n",
        "# Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")"
      ],
      "metadata": {
        "id": "FTeqhPi88ZFq"
      },
      "id": "FTeqhPi88ZFq",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\"What is the weather in Al Baha Saudi Arabia?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOwhi6lw8aQV",
        "outputId": "67887dd5-78e5-4bff-a532-a30c15557424"
      },
      "id": "wOwhi6lw8aQV",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current weather in Al Baha, Saudi Arabia is 28.4째C with a wind speed of 9.8 m/s and a wind direction of 6째. The data was last updated on September 17, 2024 at 07:45.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### - Raniyah Alghamdi\n",
        "\n",
        "### - Ziyad Alenzi\n",
        "\n",
        "### - Abdullah Owais\n",
        "\n",
        "### - Maryam Jathmi"
      ],
      "metadata": {
        "id": "ohVGYe06-tpu"
      },
      "id": "ohVGYe06-tpu"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}